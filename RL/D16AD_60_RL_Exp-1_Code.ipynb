{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6K2+F+CQFlf2RGhxny0n1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","\n","num_rows = 4\n","num_cols = 4\n","num_states = num_rows * num_cols  # 4x4 grid\n","num_actions = 4  # Up, Down, Left, Right\n","num_episodes = 500\n","alpha = 0.6  # Learning rate\n","gamma = 0.9  # Discount factor\n","\n","Q = np.zeros((num_states, num_actions), dtype=float)\n","\n","rewards = np.random.randint(1, 10, num_states)\n","\n","# Define the goal state and obstacles\n","goal_state = num_states - 1\n","obstacles = [5, 7, 10]\n","\n","# Update rewards for goal state and obstacles\n","rewards[goal_state] = 10\n","for obstacle in obstacles:\n","    rewards[obstacle] = -10\n","\n","# List to store the path taken during each episode\n","episode_paths = []\n","\n","def q_learning(num_states, num_actions, num_episodes, alpha, gamma):\n","    for episode in range(num_episodes):\n","        state = np.random.randint(0, num_states)\n","        episode_path = [state]  # Initialize path for this episode\n","\n","        while True:\n","            action = np.argmax(Q[state, :]) if np.random.rand() < 0.9 else np.random.randint(0, num_actions)\n","\n","            next_state = (state + action) % num_states\n","\n","            reward = rewards[next_state]\n","\n","            Q[state, action] = (1 - alpha) * Q[state, action] + alpha * (reward + gamma * np.max(Q[next_state, :]))\n","\n","            state = next_state\n","            episode_path.append(state)  # Add the next state to the episode path\n","\n","            if state == num_states - 1:\n","                episode_paths.append(episode_path)  # Store the episode path\n","                break\n","\n","    return Q\n","\n","learned_Q_values = q_learning(num_states, num_actions, num_episodes, alpha, gamma)\n","\n","print(\"Learned Q-values:\")\n","print(learned_Q_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"oOOJq8uOiAFM","executionInfo":{"status":"ok","timestamp":1711975468822,"user_tz":-330,"elapsed":11,"user":{"displayName":"SUBRATO TAPASWI","userId":"02223449318615464515"}},"outputId":"9312f80e-064d-4976-f0ed-67a97a2346a6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Learned Q-values:\n","[[78.88996516 80.78980777 76.8897647  82.1       ]\n"," [80.78998346 76.88971639 82.1        83.1       ]\n"," [46.13399819 82.1        77.7816     62.53471715]\n"," [82.09995945 83.09994519 70.09872244 89.        ]\n"," [82.42707128 70.09264948 89.         67.39914786]\n"," [-6.         89.         56.61585753 51.59793908]\n"," [89.         67.39999998 86.         90.        ]\n"," [50.6130068  86.         54.          0.        ]\n"," [70.93463195 90.         42.6        76.8951732 ]\n"," [90.         71.         85.         85.        ]\n"," [70.86278347 85.         84.99942957 90.        ]\n"," [84.99999946 84.99989418 90.         76.70226534]\n"," [84.99999866 90.         76.6599301  79.17371568]\n"," [90.         76.711      79.20099524 78.89      ]\n"," [76.66936199 79.13216411 78.87556821 80.79      ]\n"," [16.9416      0.         47.934      76.88999471]]\n"]}]},{"cell_type":"code","source":["# Extract the shortest path from the recorded episode paths\n","if episode_paths:\n","    shortest_path = min(episode_paths, key=len)\n","    print(\"Shortest path to goal state while learning:\")\n","    print(shortest_path)\n","\n","    # Display the states visited along the shortest path\n","    print(\"States visited along the shortest path:\")\n","    for state in shortest_path:\n","        row = state // num_cols\n","        col = state % num_cols\n","        print(f\"State: ({row}, {col})\")\n","else:\n","    print(\"No paths recorded during learning.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"UgaSXoITq_0Y","executionInfo":{"status":"ok","timestamp":1711975468822,"user_tz":-330,"elapsed":9,"user":{"displayName":"SUBRATO TAPASWI","userId":"02223449318615464515"}},"outputId":"27691ccf-81c7-49ea-e4a0-b92eadec9f9b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Shortest path to goal state while learning:\n","[15, 15]\n","States visited along the shortest path:\n","State: (3, 3)\n","State: (3, 3)\n"]}]}]}