{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11rEYo8AFf7Bl758ccTJ7FyG5oT9Nf_UG","timestamp":1711974066399},{"file_id":"1G5jL1GRbmKU9iWV2OPgEmPwZoh4f31q8","timestamp":1711915424456},{"file_id":"15Nq1Azoc629N0ZuouG_QOxh6g1QFR-Se","timestamp":1709793580143}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Value Iteration**"],"metadata":{"id":"X7eHvYUyqnOZ"}},{"cell_type":"code","source":["num_iterations = 100\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","num_rows = 4\n","num_cols = 4\n","num_states = num_rows * num_cols\n","num_actions = 4\n","num_episodes = 500\n","alpha = 0.6\n","gamma = 0.9"],"metadata":{"id":"1WBuTSEbqodD","executionInfo":{"status":"ok","timestamp":1711992357880,"user_tz":-330,"elapsed":560,"user":{"displayName":"SUBRATO TAPASWI","userId":"02223449318615464515"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Define rewards, goal state, and obstacles\n","rewards = np.random.randint(1, 10, num_states)\n","goal_state = num_states - 1\n","obstacles = [5, 7, 10]\n","rewards[goal_state] = 10\n","for obstacle in obstacles:\n","    rewards[obstacle] = -10"],"metadata":{"id":"Kn_o3VscqwH2","executionInfo":{"status":"ok","timestamp":1711992359128,"user_tz":-330,"elapsed":7,"user":{"displayName":"SUBRATO TAPASWI","userId":"02223449318615464515"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Function to convert state index to coordinates\n","def state_to_coords(state):\n","    row = state // num_cols\n","    col = state % num_cols\n","    return row, col\n","\n","# Function to convert coordinates to state index\n","def coords_to_state(row, col):\n","    return row * num_cols + col\n","\n","# Initialize policy randomly\n","policy = np.random.randint(0, num_actions, num_states)"],"metadata":{"id":"HUo7q5qlqyZk","executionInfo":{"status":"ok","timestamp":1711992359128,"user_tz":-330,"elapsed":6,"user":{"displayName":"SUBRATO TAPASWI","userId":"02223449318615464515"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Initialize value function V randomly\n","V = np.random.rand(num_states)\n","\n","# Value Iteration\n","for _ in range(num_iterations):\n","    delta = 0\n","    for s in range(num_states):\n","        v = V[s]\n","        row, col = state_to_coords(s)\n","        next_states = []\n","        if row > 0:  # Up\n","            next_states.append(coords_to_state(row - 1, col))\n","        if row < num_rows - 1:  # Down\n","            next_states.append(coords_to_state(row + 1, col))\n","        if col > 0:  # Left\n","            next_states.append(coords_to_state(row, col - 1))\n","        if col < num_cols - 1:  # Right\n","            next_states.append(coords_to_state(row, col + 1))\n","        q_values = [rewards[next_state] + gamma * V[next_state] for next_state in next_states]\n","        V[s] = max(q_values)\n","        delta = max(delta, abs(v - V[s]))\n","    if delta < 1e-6:\n","        break"],"metadata":{"id":"Xncdihl_q1e6","executionInfo":{"status":"ok","timestamp":1711992359129,"user_tz":-330,"elapsed":6,"user":{"displayName":"SUBRATO TAPASWI","userId":"02223449318615464515"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Extract optimal policy from value function\n","optimal_policy = np.zeros(num_states, dtype=int)\n","for s in range(num_states):\n","    row, col = state_to_coords(s)\n","    next_states = []\n","    if row > 0:  # Up\n","        next_states.append(coords_to_state(row - 1, col))\n","    if row < num_rows - 1:  # Down\n","        next_states.append(coords_to_state(row + 1, col))\n","    if col > 0:  # Left\n","        next_states.append(coords_to_state(row, col - 1))\n","    if col < num_cols - 1:  # Right\n","        next_states.append(coords_to_state(row, col + 1))\n","    q_values = [rewards[next_state] + gamma * V[next_state] for next_state in next_states]\n","    optimal_policy[s] = np.argmax(q_values)\n","\n","# Display the final optimal policy and values\n","optimal_policy_matrix = np.array(['U', 'D', 'L', 'R'])[optimal_policy]\n","optimal_policy_matrix = optimal_policy_matrix.reshape((num_rows, num_cols))"],"metadata":{"id":"d1wcHLnnq4Ry","executionInfo":{"status":"ok","timestamp":1711992359130,"user_tz":-330,"elapsed":7,"user":{"displayName":"SUBRATO TAPASWI","userId":"02223449318615464515"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(\"Final Optimal Policy:\")\n","print(optimal_policy_matrix)\n","print(\"\\nOptimal Values:\")\n","print(V.reshape((num_rows, num_cols)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"MNL1vWkKsu4B","executionInfo":{"status":"ok","timestamp":1711992518307,"user_tz":-330,"elapsed":495,"user":{"displayName":"SUBRATO TAPASWI","userId":"02223449318615464515"}},"outputId":"78683a34-92b6-40e1-c7c6-6a1715925b48"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Optimal Policy:\n","[['D' 'L' 'D' 'D']\n"," ['U' 'U' 'U' 'U']\n"," ['U' 'L' 'U' 'D']\n"," ['U' 'D' 'L' 'D']]\n","\n","Optimal Values:\n","[[85.26315412 84.73683871 85.26315484 84.73683936]\n"," [81.73683871 85.26315484 84.73683936 80.26315542]\n"," [76.56315484 74.90683936 77.26315542 76.31578704]\n"," [74.90683936 74.41615542 76.31578704 73.68420833]]\n"]}]}]}